{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 展示相对地址\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "# 读取csv文件\n",
    "df = pd.read_csv(current_directory + '/traceset/topology.csv')\n",
    "# 绘制散点图\n",
    "plt.scatter(df['lon'], df['lat'],s=5)\n",
    "\n",
    "# 添加标题和坐标轴标签\n",
    "plt.title('bs')\n",
    "plt.xlabel('lon')\n",
    "plt.ylabel('lat')\n",
    "\n",
    "# 显示图形\n",
    "plt.show()\n",
    "plt.savefig(current_directory + '/origin.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将时间进行转换，并且只保留packets\n",
    "\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta, timezone\n",
    "\n",
    "# 定义北京时区\n",
    "tz_beijing = timezone(timedelta(hours=8))\n",
    "\n",
    "current_directory = os.getcwd()\n",
    "# 读取csv文件\n",
    "df = pd.read_csv( current_directory + '/traceset/cellular_traffic.csv')\n",
    "\n",
    "# 定义一个函数，将UNIX纪元时间转换为常规日期和时间\n",
    "def convert_time(time_hour):\n",
    "    dt = datetime.fromtimestamp(time_hour, tz=tz_beijing)\n",
    "    return dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# 应用函数，将time_hour列转换为常规日期和时间\n",
    "df['time_hour'] = df['time_hour'].apply(convert_time)\n",
    "\n",
    "df_pivot = df.pivot(index='time_hour', columns='bs', values='packets')\n",
    "\n",
    "# 将结果保存到新的csv文件中\n",
    "df_pivot.to_csv(current_directory + '/beijing_cellular_traffic.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 只保留拥有足够数据的bs\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "current_directory = os.getcwd()\n",
    "# 读取csv文件\n",
    "df = pd.read_csv(current_directory + '/beijing_cellular_traffic.csv',index_col=0)\n",
    "\n",
    "# 筛选出超过67个有效单元格的基站id\n",
    "valid_bs = df.count(axis=0)\n",
    "valid_bs = valid_bs[valid_bs > 67]\n",
    "\n",
    "# # 输出到txt文件\n",
    "# with open('valid_bs.txt', 'w') as f:\n",
    "#     for bs, count in valid_bs.items():\n",
    "#         f.write(f'{bs}, {count}\\n')\n",
    "        \n",
    "# 保留有效的基站id列\n",
    "df = df[valid_bs.index]\n",
    "\n",
    "# 输出到csv文件\n",
    "df.to_csv(current_directory + '/valid_bs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 展示离群值，需要忽略掉nan，否则会影响箱线图\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "current_directory = os.getcwd()\n",
    "# 读取csv文件\n",
    "df = pd.read_csv(current_directory + '/valid_bs.csv',index_col=0)\n",
    "\n",
    "# 将时间戳索引转换为datetime对象，并提取小时数\n",
    "df.index = pd.to_datetime(df.index)\n",
    "hours = df.index.hour\n",
    "\n",
    "# 创建一个空的列表来保存按小时分组的数据\n",
    "grouped = [df[hours == hour].values.flatten() for hour in range(24)]\n",
    "grouped = [values[~np.isnan(values)] for values in grouped]\n",
    "\n",
    "# print(grouped)\n",
    "# 制作箱线图\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.boxplot(grouped, labels=range(24), positions=range(24))\n",
    "plt.title('Boxplot of Packet Counts by Hour')\n",
    "plt.xlabel('Hour')\n",
    "plt.ylabel('Packet Count')\n",
    "plt.xticks(range(24))  # 设置x轴的刻度位置和标签为0~23小时\n",
    "plt.show()\n",
    "\n",
    "plt.savefig( current_directory + '/outlier.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 去除离群值\n",
    "\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "current_directory = os.getcwd()\n",
    "# 读取csv文件\n",
    "df = pd.read_csv(current_directory + '/valid_bs.csv',index_col=0)\n",
    "\n",
    "\n",
    "# 计算Z-score\n",
    "z_scores = stats.zscore(df,nan_policy='omit')\n",
    "# print(z_scores)\n",
    "# 设置阈值\n",
    "threshold = 3\n",
    "\n",
    "# 将Z-score大于阈值的值设置为NaN\n",
    "df[(np.abs(z_scores) > threshold)] = np.nan\n",
    "# 输出到csv文件\n",
    "df.to_csv(current_directory + '/valid_removeoutlier_bs.csv')\n",
    "\n",
    "# # 找到值超过800000的基站id和对应的时间戳\n",
    "# result = df[df > 400000].stack().reset_index()\n",
    "# # 输出结果\n",
    "# print(result)\n",
    "\n",
    "# 将时间戳索引转换为datetime对象，并提取小时数\n",
    "df.index = pd.to_datetime(df.index)\n",
    "hours = df.index.hour\n",
    "# 创建一个空的列表来保存按小时分组的数据\n",
    "grouped = [df[hours == hour].values.flatten() for hour in range(24)]\n",
    "grouped = [values[~np.isnan(values)] for values in grouped]\n",
    "# 制作箱线图\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.boxplot(grouped, labels=range(24), positions=range(24))\n",
    "plt.title('Boxplot of Packet Counts by Hour')\n",
    "plt.xlabel('Hour')\n",
    "plt.ylabel('Packet Count')\n",
    "plt.xticks(range(24))  # 设置x轴的刻度位置和标签为0~23小时\n",
    "plt.show()\n",
    "\n",
    "plt.savefig(current_directory + '/valid_removeoutlier_bs.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 填充NAN\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "current_directory = os.getcwd()\n",
    "# 读取csv文件\n",
    "df = pd.read_csv(current_directory + '/valid_removeoutlier_bs.csv', index_col=0)\n",
    "\n",
    "# 将NaN值替换为前一个小时的值\n",
    "df.fillna(method='ffill', inplace=True)\n",
    "\n",
    "# 删除包含NaN值的列\n",
    "df = df.dropna(axis=1)\n",
    "print(df.shape)\n",
    "# # 找到值为NaN的行和列\n",
    "# nan_rows = df[df.isnull().any(axis=1)]\n",
    "# nan_cols = df.columns[df.isnull().any()].tolist()\n",
    "\n",
    "# print('Rows with NaN values:')\n",
    "# print(nan_rows)\n",
    "\n",
    "# print('Columns with NaN values:')\n",
    "# print(nan_cols)\n",
    "\n",
    "# 将时间戳索引转换为datetime对象，并提取小时数\n",
    "df.index = pd.to_datetime(df.index)\n",
    "hours = df.index.hour\n",
    "# 创建一个空的列表来保存按小时分组的数据\n",
    "grouped = [df[hours == hour].values.flatten() for hour in range(24)]\n",
    "grouped = [values[~np.isnan(values)] for values in grouped]\n",
    "\n",
    "# 制作箱线图\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.boxplot(grouped, labels=range(24), positions=range(24))\n",
    "plt.title('Boxplot of Packet Counts by Hour')\n",
    "plt.xlabel('Hour')\n",
    "plt.ylabel('Packet Count')\n",
    "plt.xticks(range(24))  # 设置x轴的刻度位置和标签为0~23小时\n",
    "plt.show()\n",
    "\n",
    "plt.savefig(current_directory + '/fill_nan.png')\n",
    "\n",
    "df.to_csv(current_directory + '/fill_nan.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalization\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import os\n",
    "current_directory = os.getcwd()\n",
    "# 读取csv文件\n",
    "df = pd.read_csv(current_directory + '/fill_nan.csv', index_col=0)\n",
    "# 创建一个MinMaxScaler对象\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# 对DataFrame的所有列进行归一化\n",
    "df = pd.DataFrame(scaler.fit_transform(df), columns=df.columns, index=df.index)\n",
    "\n",
    "\n",
    "df.index = pd.to_datetime(df.index)\n",
    "hours = df.index.hour\n",
    "# 创建一个空的列表来保存按小时分组的数据\n",
    "grouped = [df[hours == hour].fillna(0).values.flatten() for hour in range(24)]\n",
    "# 制作箱线图\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.boxplot(grouped, labels=range(24), positions=range(24))\n",
    "plt.title('Boxplot of Packet Counts by Hour')\n",
    "plt.xlabel('Hour')\n",
    "plt.ylabel('Packet Count')\n",
    "plt.xticks(range(24))  # 设置x轴的刻度位置和标签为0~23小时\n",
    "plt.show()\n",
    "\n",
    "# 保存新的CSV文件\n",
    "df.to_csv(current_directory + '/normalized_file.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "import datetime\n",
    "\n",
    "def init_logger(filename, logger_name):\n",
    "    '''\n",
    "    @brief:\n",
    "        initialize logger that redirect info to a file just in case we lost connection to the notebook\n",
    "    @params:\n",
    "        filename: to which file should we log all the info\n",
    "        logger_name: an alias to the logger\n",
    "    '''\n",
    "    # 创建一个logger\n",
    "    logger = logging.getLogger(logger_name)\n",
    "    logger.setLevel(logging.DEBUG)  # 设置日志级别\n",
    "    logger.propagate = False  # 禁止日志传播\n",
    "    # 创建一个handler，用于写入日志文件\n",
    "    fh = logging.FileHandler(filename)\n",
    "    fh.setLevel(logging.DEBUG)  # 设置handler的日志级别\n",
    "\n",
    "    # 创建一个formatter，用于设置日志格式\n",
    "    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "\n",
    "    # 将formatter添加到handler\n",
    "    fh.setFormatter(formatter)\n",
    "\n",
    "    # 将handler添加到logger\n",
    "    logger.addHandler(fh)\n",
    "    logger.info('### Init. Logger {} ###'.format(logger_name))\n",
    "    return logger\n",
    "\n",
    "# Initialize\n",
    "czh_logger = init_logger(\"czh_notebook.log\", \"czh_logger\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tslearn.clustering import TimeSeriesKMeans\n",
    "from tslearn.metrics import dtw\n",
    "from sklearn.metrics import silhouette_score\n",
    "import os\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "# 读取csv文件\n",
    "df = pd.read_csv(current_directory + '/normalized_file.csv', index_col=0)\n",
    "czh_logger.info(df.shape) # (192, 7521) ，论文示例显示是2,071个，说明我筛选力度不够大\n",
    "# 将数据转换为适合tslearn处理的格式\n",
    "formatted_data = df.T.values.reshape((df.shape[1], df.shape[0], 1))\n",
    "\n",
    "clusters = 5\n",
    "# 定义并训练模型\n",
    "model = TimeSeriesKMeans(n_clusters=clusters, metric='dtw', verbose=False, max_iter=5, max_iter_barycenter=5, random_state=0)\n",
    "labels = model.fit_predict(formatted_data)\n",
    "# czh_logger.info(labels) arrary 输出不全，需要转换成label\n",
    "\n",
    "\n",
    "# 将基站id和分类结果写入到文件中\n",
    "with open(current_directory + '/cluster_label.txt', 'w') as f:\n",
    "    for bs_id, label in zip(df.columns, labels):\n",
    "        f.write(f'{bs_id}, {label}\\n')\n",
    "czh_logger.info(labels.shape)\n",
    "\n",
    "# 计算Silhouette index，时间的大头花在这里\n",
    "# silhouette_avg = silhouette_score(df.T, labels, metric=dtw) # (n_samples_a, n_features)\n",
    "# czh_logger.info(f\"Silhouette index: {silhouette_avg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tslearn.generators import random_walks\n",
    "from tslearn.clustering import TimeSeriesKMeans\n",
    "from tslearn.metrics import dtw\n",
    "import os\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "X = random_walks(n_ts=1, sz=192, d=1)\n",
    "\n",
    "model = TimeSeriesKMeans(n_clusters=3, metric=\"dtw\", max_iter=5,\n",
    "                          max_iter_barycenter=5,\n",
    "                          random_state=0)\n",
    "labels = model.fit_predict(X)\n",
    "\n",
    "\n",
    "czh_logger.info(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "\n",
    "\n",
    "# 输出一条日志\n",
    "logger.info('This is a log message.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
